{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "Notes\n",
    "- Add 5 second delays before requesting from AO3's server are in compliance with the AO3 terms of service.\n",
    "- Cannot scrape restricted fics, which require login. Can use https://pypi.org/project/ao3/ to log in but cannot use it to scrape restricted fics.\n",
    "- Some accounts no longer exist. i.e. ``ButterflyPup``.\n",
    "- account name ``orphan_account`` is a default pseud of the Orphan Account for works that are no longer associated with their creator's account. Skipped it for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import pprint\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import argparse\n",
    "import time\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "from unidecode import unidecode\n",
    "from itertools import groupby\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path_to_stories = sys.argv[-1]\n",
    "path_to_stories = 'sampledata/ao3_harrypotter_text_stories.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_authors_from_storiescsv(path_to_stories):\n",
    "    '''\n",
    "    param: path to stories.csv\n",
    "    return: a Series of author_keys with duplicates removed\n",
    "    '''\n",
    "    return pd.read_csv(path_to_stories,usecols = ['author_key'])['author_key'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "authorschema = ('author_key',\n",
    "                'pseudos',\n",
    "                'bday',\n",
    "                'author_fic_ids',\n",
    "                'joined_on',\n",
    "                'live_in',\n",
    "                'author_work_count',\n",
    "                'author_bookmark_count',\n",
    "                'bio',\n",
    "                'linked_social_media')\n",
    "\n",
    "pseudoschema = ('author_key',\n",
    "                   'pseudo',\n",
    "                   'pd_work_count',\n",
    "                   'pd_bookmark_count',\n",
    "                   'pd_fic_ids')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_bookmark_work_counts(soup, author_key, pseudo = None):\n",
    "    \n",
    "    \n",
    "    if pseudo == None:\n",
    "        url = \"/users/\" + author_key\n",
    "    else:\n",
    "        url = \"/users/\" + author_key + \"/pseuds/\" + pseudo\n",
    "        \n",
    "    # get the # of fics this author/pseudo has bookmarked\n",
    "    try:\n",
    "        bookmark_cnt = soup.find(\"a\", attrs = {'href': lambda x: x and x.lower() == url.lower() + \"/bookmarks\"}).text \n",
    "        bookmark_cnt = bookmark_cnt[11:-1]\n",
    "    except:\n",
    "        print('Error finding bookmarks of', url + \"/bookmarks\")\n",
    "    \n",
    "    # get the # of fics this author/pseduo has created (incl. WIP)\n",
    "    try:\n",
    "        work_cnt = soup.find(\"a\", attrs = {'href': lambda x: x and x.lower() == url.lower() + \"/works\"}).text # i.e. \"Works (1)\"\n",
    "        work_cnt = work_cnt[7:-1]\n",
    "    except:\n",
    "        print('Error finding bookmarks of' + url + \"/works\")\n",
    "    \n",
    "    return bookmark_cnt, work_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrape_an_author(author_key,\n",
    "                     authorschema = authorschema,\n",
    "                     pseudoschema = pseudoschema):\n",
    "    '''\n",
    "    param: author_key (str)\n",
    "    return: df of the author, linked_social_media left as None\n",
    "    each row is an author identity (author_key and psudo pair)\n",
    "    '''\n",
    "    \n",
    "    author = pd.DataFrame(columns= authorschema)\n",
    "    pseudoddf = pd.DataFrame(columns= pseudoschema)\n",
    "    \n",
    "    # ==== profile the author ==== #\n",
    "    # get start_date, location\n",
    "    r1 = requests.get(\"https://archiveofourown.org/users/\" + author_key + \"/profile\",\n",
    "                      headers = { 'User-Agent': 'Mozilla/5.0 (Windows NT 6.0; WOW64; rv:24.0) Gecko/20100101 Firefox/24.0'})\n",
    "    soup1 = BeautifulSoup(r1.content, \"html.parser\")\n",
    "    \n",
    "    try:\n",
    "        # if the author_key exists\n",
    "        umeta = [dd.text for dd in soup1.find(\"dl\", class_=\"meta\").findAll(\"dd\")]\n",
    "        # print('Found author %s.'%author_key)\n",
    "    except:\n",
    "        print ('Cannot find author %s.'%author_key)\n",
    "        return None, None\n",
    "    \n",
    "    start_date = umeta[1]\n",
    "    try:\n",
    "        location = umeta[2]\n",
    "    except:\n",
    "        location = \"\"\n",
    "        \n",
    "    # get all pseudos of the author_key\n",
    "    pseudos = [i['href'].split('/')[-1] for i in soup1.find(\"dd\", class_ = \"pseuds\").findAll(\"a\")]\n",
    "    \n",
    "    # find the author's bio, if any\n",
    "    biosoup = soup1.find(\"blockquote\", class_ = \"userstuff\")\n",
    "    if biosoup is not None:\n",
    "        try:\n",
    "            bio = biosoup.text\n",
    "        except Exception as e:\n",
    "            print(author_key, e)\n",
    "            bio = \"<!ERROR!>\"\n",
    "    else:\n",
    "        bio = \"\"\n",
    "        \n",
    "    # find the author's bday, if listed\n",
    "    try:\n",
    "        bday = soup1.find(\"dd\", class_=\"birthday\").text\n",
    "    except:\n",
    "        bday = \"\"\n",
    "    \n",
    "    author_bookmark_cnt, author_work_cnt = find_bookmark_work_counts(soup1, author_key)\n",
    "    \n",
    "    author = author.append({'author_key': author_key,\n",
    "                            'bday': bday,\n",
    "                            'pseudos': pseudos,\n",
    "                            'joined_on': start_date,\n",
    "                            'live_in': location,\n",
    "                            'author_work_count': author_work_cnt,\n",
    "                            'author_bookmark_count': author_bookmark_cnt,\n",
    "                            'fic_ids': None, #todo\n",
    "                            'bio': bio,\n",
    "                            'linked_social_media': None},\n",
    "                             ignore_index = True)\n",
    "    \n",
    "    # ==== profile the author ==== #\n",
    "    for pseudo in pseudos:\n",
    "        \n",
    "        r2 = requests.get(\"https://archiveofourown.org/users/\" + author_key + \"/pseuds/\" + pseudo,\n",
    "                      headers = { 'User-Agent': 'Mozilla/5.0 (Windows NT 6.0; WOW64; rv:24.0) Gecko/20100101 Firefox/24.0'})\n",
    "        soup2 = BeautifulSoup(r2.content, \"html.parser\")\n",
    "        \n",
    "        pd_bookmark_cnt, pd_work_cnt = find_bookmark_work_counts(soup2, author_key, pseudo)\n",
    "        \n",
    "        pseudoddf = pseudoddf.append({'author_key': author_key,\n",
    "                                      'pseudo': pseudo,\n",
    "                                      'pd_work_count': pd_work_cnt,\n",
    "                                      'pd_bookmark_count': pd_bookmark_cnt,\n",
    "                                      'pd_fic_ids': None\n",
    "                                     },\n",
    "                                     ignore_index = True)\n",
    "\n",
    "    return author, pseudoddf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(  author_key                     pseudos bday author_fic_ids   joined_on  \\\n",
       " 0  Falmarien  [falmarien, Navi, saoirse]                 NaN  2011-12-03   \n",
       " \n",
       "         live_in author_work_count author_bookmark_count  \\\n",
       " 0  Cerin Amroth                25                   216   \n",
       " \n",
       "                                                  bio linked_social_media  \\\n",
       " 0  tumblr: rainblownfieldsdreamwidth: falmarienol...                None   \n",
       " \n",
       "   fic_ids  \n",
       " 0    None  ,\n",
       "   author_key     pseudo pd_work_count pd_bookmark_count pd_fic_ids\n",
       " 0  Falmarien  falmarien            10               207       None\n",
       " 1  Falmarien       Navi            15                 9       None\n",
       " 2  Falmarien    saoirse             0                 0       None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test cases:\n",
    "# - allmylovesatonce 39 works\n",
    "# - alexdesro08 2 pseudos, no works finished\n",
    "# - liketolaugh 103 works (Interview study participant)\n",
    "\n",
    "# scrape_an_author('allmylovesatonce')\n",
    "# scrape_an_author('liketolaugh')\n",
    "# scrape_an_author('alexdesro08')\n",
    "# scrape_an_author('Tara')[1]\n",
    "scrape_an_author('Falmarien')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "Cannot find author ButterflyPup.\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "Cannot find author Aisling_Isobel.\n",
      "99\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "author_key_list = get_authors_from_storiescsv(path_to_stories)\n",
    "\n",
    "authors = pd.DataFrame(columns= authorschema)\n",
    "pseudos = pd.DataFrame(columns= pseudoschema)\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "for author_key in author_key_list:\n",
    "    if cnt >= 100:\n",
    "        break\n",
    "    \n",
    "    if author_key == 'orphan_account':\n",
    "        # skip ``orphan_account`` \n",
    "        # which is a default pseud of the Orphan Account for works that are no longer associated with their creator's account.\n",
    "        pass\n",
    "    else:\n",
    "        author, pseudo = scrape_an_author(author_key)\n",
    "        authors = authors.append(author)\n",
    "        pseudos= pseudos.append(pseudo)\n",
    "        cnt += 1\n",
    "        print(cnt)\n",
    "\n",
    "authors.to_csv('sampleoutput/sampleoutput_authors.csv', mode='w+', header=False, index=False)\n",
    "pseudos.to_csv('sampleoutput/sampleoutput_pseudos.csv', mode='w+', header=False, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
